---
title: "Second Test"
subtitle: "Prof: Luiz Peternelli"
author: "Marco Guerra Hinostroza"
date: "`r Sys.Date()`"
format:
  html:
    embed-resources: true
    toc: true
    toc-location: left
    number-sections: false
    code-fold: false
    filters:
        - highlight-text
editor_options: 
  chunk_output_type: console
---
```{r, echo=FALSE, message=FALSE}
library(tidyverse)
```

## Question 1

```{r}
data <- read.table("dados.full-preparadoP2.csv", sep = ";", header = T)
data <- data %>%
  mutate(across(c(nc, ac, dc, tchr), ~ as.numeric(gsub(",", ".", .))))
str(data)
```

```{r}
set.seed(1)
sorteio <- sample(1:length(data$tchr), replace = FALSE)
```

```{r, warning=FALSE}
k <- 5
cvs <- split(sorteio,1:k)
cv <- 1:k 
```

```{r}
grau.polinomio <- 5
cv.error.5 <- matrix (NA, nrow = k, ncol = grau.polinomio)
```

```{r}
for (k in cv) { 
  for (i in 1:grau.polinomio) {
    
    glm.fit <- glm(tchr ~ poly(nc ,i), data = data[-c(cvs[[k]]),])
    
    cv.error.5[k,i] <- mean((data$tchr-predict(glm.fit, data))[cvs[[k]]]^2, na.rm = T)
    
  }
}
```

```{r}
cv.error.5
```

```{r}
matplot(1:grau.polinomio, t(cv.error.5), type = "b", pch = 1,
        ylab = "Mean Squared Error", xlab = "Degree of Polynomial")
```

```{r}
colMeans(cv.error.5)
```


```{r}
diag(var(cv.error.5))
```

## Question 2

```{r}
cv.error.nc <- matrix(NA, nrow = k, ncol = grau.polinomio)
for (k in cv) { 
  for (i in 1:grau.polinomio) {
    glm.fit <- glm(tchr ~ poly(nc ,i), data = data[-c(cvs[[k]]),])
    cv.error.nc[k,i] <- mean((data$tchr-predict(glm.fit, data))[cvs[[k]]]^2, na.rm = T)
  }
}
melhor_grau_nc <- which.min(colMeans(cv.error.nc))

cv.error.ac <- matrix(NA, nrow = k, ncol = grau.polinomio)
for (k in cv) { 
  for (i in 1:grau.polinomio) {
    glm.fit <- glm(tchr ~ poly(ac ,i), data = data[-c(cvs[[k]]),])
    cv.error.ac[k,i] <- mean((data$tchr-predict(glm.fit, data))[cvs[[k]]]^2, na.rm = T)
  }
}
melhor_grau_ac <- which.min(colMeans(cv.error.ac))

cv.error.dc <- matrix(NA, nrow = k, ncol = grau.polinomio)
for (k in cv) { 
  for (i in 1:grau.polinomio) {
    glm.fit <- glm(tchr ~ poly(dc ,i), data = data[-c(cvs[[k]]),])
    cv.error.dc[k,i] <- mean((data$tchr-predict(glm.fit, data))[cvs[[k]]]^2, na.rm = T)
  }
}
melhor_grau_dc <- which.min(colMeans(cv.error.dc))
```


```{r}
formula_final <- as.formula(paste(
  "tchr ~ poly(nc,", melhor_grau_nc, ") +",
  "poly(ac,", melhor_grau_ac, ") +",
  "poly(dc,", melhor_grau_dc, ")"
))
formula_final
```


```{r}
cv.error.final <- matrix(NA, nrow = k, ncol = 1)

for (k in cv) {
  glm.final <- glm(formula_final, data = data[-c(cvs[[k]]), ])
  cv.error.final[k, 1] <- mean((data$tchr - predict(glm.final, data))[cvs[[k]]]^2, na.rm = TRUE)
}

cv.error.final

mean(cv.error.final)

```

**Is this new model (from problem 2) better than any of the models in problem 1?**

It is better because it has a lower MSE. That is, the [glm.final]{colour="#FFFFFF" bg-colour="#009999"} model makes better predictions on test set than any of the other models proposed in item **a**.

## Question 3

### Problem a
```{r}
train <- data |> filter(exp != 1)
test <- data |> filter(exp == 1)
```

```{r}
glm3 <- glm(tchr ~ poly(nc, 2) + poly(ac, 1) + poly(dc, 1), data = train)
```

```{r}
summary(glm3)
```

```{r}
testp <- test |> mutate(predicted_tchr = predict(glm3, newdata = test, type = "response"))
```

```{r}
error <- mean((testp$tchr - testp$predicted_tchr)^2)
error
```

### Problem b

```{r}
variaveis <- train |> select(tchr, nc, dc, ac)
matriz_cov <- cov(variaveis)
matriz_cov
```

```{r}
summary(train[,4:7])
```

```{r}
gera.mult.chol<-function(vu, sigma, iter)
  {
  mu <- vu
  fc <- chol(sigma)
  iter <- iter
  p <- length(fc[1,])
  variaveis <- matrix(99, iter, p)
  for (i in 1:iter)
    {
    z <- rnorm(p)
    variaveis[i,] <- mu+t(fc)%*%z 
    }
  return(variaveis)
}
```

```{r}
simulations <- c(500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000)

mu <- c(108.35, 108.2, 25.28, 2.527)

set.seed(2)
for (sim in simulations){
  j <- gera.mult.chol(mu, matriz_cov, sim)
  temp_df <- as.data.frame(j) |> rename(tchr = V1, nc = V2, dc = V3, ac = V4)
  assign(paste0("j_", sim), temp_df)
}

calcular_error <- function(data){
  modelo <- glm(tchr ~ poly(nc, 2) + poly(ac, 1) + poly(dc, 1), data = data)
  test <- test |> mutate(predicted_tchr = predict(modelo, newdata = test, type = "response"))
  error <- mean((test$tchr - test$predicted_tchr)^2)
  return(error)
}

datasets <- list(j_500, j_1000, j_1500, j_2000, j_2500,
                 j_3000, j_3500, j_4000, j_4500, j_5000)

e <- lapply(datasets, calcular_error)
```

Synthetic data helps to increase the accuracy of predictions (<MSE) compared to the value of 87.0078 when using just the available data.
```{r}
matplot(simulations, unlist(e), type = "b", col = "blue", pch = 9,
        xlab = "Number of simulated values", ylab = "Mean Squared Error", 
        main = "Error by Number of simulated values")
```


However, an increase in the amount of simulated data does not necessarily result in a progressive improvement in prediction accuracy, as demonstrated below using a another [set.seed()]{colour="#FFFFFF" bg-colour="#009999"}.
```{r}
set.seed(5)
for (sim in simulations){
  j <- gera.mult.chol(mu, matriz_cov, sim)
  temp_df <- as.data.frame(j) |> rename(tchr = V1, nc = V2, dc = V3, ac = V4)
  assign(paste0("j_", sim), temp_df)
}

datasets <- list(j_500, j_1000, j_1500, j_2000, j_2500,
                 j_3000, j_3500, j_4000, j_4500, j_5000)

e <- lapply(datasets, calcular_error)

matplot(simulations, unlist(e), type = "b", col = "blue", pch = 9,
        xlab = "Number of simulated values", ylab = "Mean Squared Error", 
        main = "Error by Number of simulated values")
```


